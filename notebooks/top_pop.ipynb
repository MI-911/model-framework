{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Init dataloader with 17652 ratings\n \n            DataLoader Information\n            -----------------------------------\n            n_users:                      929\n            n_movies:                     2993\n            n_descriptive_entities:       0\n\n            n_ratings:                    17652\n            n_movie_ratings:              17652\n            n_descriptive_entity_ratings: 0\n        \n",
      "Asserting positive samples not in training set for each user...\nAsserting negative samples occurrence in training set, but not rated for each user...\n",
      "Asserting positive samples do not occur in negative samples...\nReturning a dataset over 927 users.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from data_loading.loo_data_loader import DesignatedDataLoader\n",
    "data_loader = DesignatedDataLoader.load_from(\n",
    "    path='../data_loading/mindreader',\n",
    "    movies_only=True,\n",
    "    min_num_entity_ratings=1,\n",
    "    filter_unknowns=True\n",
    ")\n",
    "\n",
    "data_loader.random_seed = 345\n",
    "\n",
    "print(data_loader.info())\n",
    "\n",
    "train, validation, test = data_loader.make(\n",
    "    movie_to_entity_ratio=1,\n",
    "    n_negative_samples=99\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-25219610dd6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_top_pop(train_list):\n",
    "    movie_count = defaultdict(int)\n",
    "\n",
    "    for user, ratings in train_list:\n",
    "        for rating in ratings:\n",
    "            movie_count[rating.e_idx] += 1\n",
    "\n",
    "    return movie_count\n",
    "\n",
    "def rank(items, top_pop):\n",
    "    items = set(items)\n",
    "    item_scores = {item: score for item, score in top_pop.items() if item in items}\n",
    "    \n",
    "    return sorted(item_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "top = get_top_pop(train)\n",
    "k = 10\n",
    "\n",
    "def evaluate(eval_list):\n",
    "    hits = 0\n",
    "    count = 0\n",
    "    \n",
    "    for user, test_neg in eval_list:\n",
    "        to_hit = test_neg[0]\n",
    "        \n",
    "        ranks = [item[0] for item in rank([to_hit] + test_neg[1], top)[:k]]\n",
    "        if to_hit in ranks:\n",
    "            hits += 1\n",
    "        count += 1\n",
    "        \n",
    "    return hits, count\n",
    "        \n",
    "\n",
    "h, c = evaluate(test)\n",
    "\n",
    "print(f'{h / c * 100}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}